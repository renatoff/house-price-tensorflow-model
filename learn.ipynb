{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LAMD6bPeXvfV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IfbmRNg84mtG"
      },
      "outputs": [],
      "source": [
        "# Set seeds for reproducibility\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "import os\n",
        "\n",
        "# Ensure reproducibility by configuring deterministic operations\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qoo29IBBX1xT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "K-GajPbmX_0H",
        "outputId": "6cea96d1-be31-4941-9a35-835bd562bc44"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>551962.99</td>\n",
              "      <td>563834.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>322875.00</td>\n",
              "      <td>460943.46</td>\n",
              "      <td>654962.50</td>\n",
              "      <td>26590000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>2.16</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2.50</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>2139.35</td>\n",
              "      <td>963.21</td>\n",
              "      <td>370.0</td>\n",
              "      <td>1460.00</td>\n",
              "      <td>1980.00</td>\n",
              "      <td>2620.00</td>\n",
              "      <td>13540.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>14852.52</td>\n",
              "      <td>35884.44</td>\n",
              "      <td>638.0</td>\n",
              "      <td>5000.75</td>\n",
              "      <td>7683.00</td>\n",
              "      <td>11001.25</td>\n",
              "      <td>1074218.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>floors</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.54</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.50</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterfront</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>view</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_above</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>1827.27</td>\n",
              "      <td>862.17</td>\n",
              "      <td>370.0</td>\n",
              "      <td>1190.00</td>\n",
              "      <td>1590.00</td>\n",
              "      <td>2300.00</td>\n",
              "      <td>9410.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_basement</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>312.08</td>\n",
              "      <td>464.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>610.00</td>\n",
              "      <td>4820.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_built</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>1970.79</td>\n",
              "      <td>29.73</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>1951.00</td>\n",
              "      <td>1976.00</td>\n",
              "      <td>1997.00</td>\n",
              "      <td>2014.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_renovated</th>\n",
              "      <td>4600.0</td>\n",
              "      <td>808.61</td>\n",
              "      <td>979.41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1999.00</td>\n",
              "      <td>2014.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                count       mean        std     min        25%        50%  \\\n",
              "price          4600.0  551962.99  563834.70     0.0  322875.00  460943.46   \n",
              "bedrooms       4600.0       3.40       0.91     0.0       3.00       3.00   \n",
              "bathrooms      4600.0       2.16       0.78     0.0       1.75       2.25   \n",
              "sqft_living    4600.0    2139.35     963.21   370.0    1460.00    1980.00   \n",
              "sqft_lot       4600.0   14852.52   35884.44   638.0    5000.75    7683.00   \n",
              "floors         4600.0       1.51       0.54     1.0       1.00       1.50   \n",
              "waterfront     4600.0       0.01       0.08     0.0       0.00       0.00   \n",
              "view           4600.0       0.24       0.78     0.0       0.00       0.00   \n",
              "condition      4600.0       3.45       0.68     1.0       3.00       3.00   \n",
              "sqft_above     4600.0    1827.27     862.17   370.0    1190.00    1590.00   \n",
              "sqft_basement  4600.0     312.08     464.14     0.0       0.00       0.00   \n",
              "yr_built       4600.0    1970.79      29.73  1900.0    1951.00    1976.00   \n",
              "yr_renovated   4600.0     808.61     979.41     0.0       0.00       0.00   \n",
              "\n",
              "                     75%         max  \n",
              "price          654962.50  26590000.0  \n",
              "bedrooms            4.00         9.0  \n",
              "bathrooms           2.50         8.0  \n",
              "sqft_living      2620.00     13540.0  \n",
              "sqft_lot        11001.25   1074218.0  \n",
              "floors              2.00         3.5  \n",
              "waterfront          0.00         1.0  \n",
              "view                0.00         4.0  \n",
              "condition           4.00         5.0  \n",
              "sqft_above       2300.00      9410.0  \n",
              "sqft_basement     610.00      4820.0  \n",
              "yr_built         1997.00      2014.0  \n",
              "yr_renovated     1999.00      2014.0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe().T.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7UbpPU4WzDEq"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['country', 'street'], inplace=True)\n",
        "for col in ['bedrooms', 'bathrooms', 'floors']:\n",
        "    df[col] = df[col].apply(lambda x:int(x))\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['year_sold'] = df['date'].dt.year\n",
        "df['month_sold'] = df['date'].dt.month\n",
        "df['day_sold'] = df['date'].dt.day\n",
        "df = df.drop(columns=['date'])\n",
        "df = pd.get_dummies(df, columns=['city', 'statezip'], drop_first=True)\n",
        "df['house_age'] = df['year_sold'] - df['yr_built']\n",
        "df['years_since_renovation'] = df['year_sold'] - df['yr_renovated']\n",
        "df['years_since_renovation'] = df['years_since_renovation'].apply(lambda x: x if x >= 0 else 0)\n",
        "df['has_basement'] = df['sqft_basement'].apply(lambda x: 1 if x > 0 else 0)\n",
        "df['total_sqft'] = df['sqft_living'] + df['sqft_lot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fY1ZlEr_3Y6o"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Example using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['sqft_living', 'sqft_lot', 'floors', 'waterfront',\n",
        "                      'view', 'condition', 'sqft_above', 'sqft_basement',\n",
        "                      'yr_built', 'yr_renovated', 'year_sold', 'month_sold',\n",
        "                      'day_sold', 'house_age', 'years_since_renovation', 'total_sqft']\n",
        "\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zdR9E9jcZYY8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(columns=['price'])\n",
        "y = df['price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8qNO-ne3tJr",
        "outputId": "8111bc73-e7cf-4406-894e-9cf9b5fe7406"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\renat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=10,         # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Restore model weights from the epoch with the best validation loss\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myt6wsc53wDS",
        "outputId": "1b454611-98f6-47ae-a3b4-eee4098eacd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 453873827840.0000 - mae: 543999.7500 - val_loss: 401507418112.0000 - val_mae: 536806.6250\n",
            "Epoch 2/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453860327424.0000 - mae: 543988.4375 - val_loss: 401463607296.0000 - val_mae: 536768.5000\n",
            "Epoch 3/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453796069376.0000 - mae: 543934.2500 - val_loss: 401333452800.0000 - val_mae: 536654.8125\n",
            "Epoch 4/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453628297216.0000 - mae: 543792.5625 - val_loss: 401061117952.0000 - val_mae: 536417.1875\n",
            "Epoch 5/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453297963008.0000 - mae: 543513.3125 - val_loss: 400587259904.0000 - val_mae: 536003.0000\n",
            "Epoch 6/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 452742873088.0000 - mae: 543043.3750 - val_loss: 399850471424.0000 - val_mae: 535358.6250\n",
            "Epoch 7/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 451901489152.0000 - mae: 542330.0625 - val_loss: 398800125952.0000 - val_mae: 534438.5625\n",
            "Epoch 8/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 450723643392.0000 - mae: 541329.7500 - val_loss: 397391331328.0000 - val_mae: 533201.9375\n",
            "Epoch 9/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449163460608.0000 - mae: 540001.7500 - val_loss: 395582373888.0000 - val_mae: 531609.8125\n",
            "Epoch 10/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 447178833920.0000 - mae: 538307.2500 - val_loss: 393335275520.0000 - val_mae: 529625.6250\n",
            "Epoch 11/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 444731621376.0000 - mae: 536210.4375 - val_loss: 390617169920.0000 - val_mae: 527215.5000\n",
            "Epoch 12/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 441788825600.0000 - mae: 533677.9375 - val_loss: 387399647232.0000 - val_mae: 524348.1875\n",
            "Epoch 13/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 438322167808.0000 - mae: 530679.4375 - val_loss: 383659540480.0000 - val_mae: 520995.5938\n",
            "Epoch 14/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 434309201920.0000 - mae: 527187.1250 - val_loss: 379379351552.0000 - val_mae: 517132.3125\n",
            "Epoch 15/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 429731315712.0000 - mae: 523174.9688 - val_loss: 374531883008.0000 - val_mae: 512722.1250\n",
            "Epoch 16/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 424556527616.0000 - mae: 518602.6562 - val_loss: 369098948608.0000 - val_mae: 507734.1250\n",
            "Epoch 17/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 418777300992.0000 - mae: 513448.5938 - val_loss: 363090542592.0000 - val_mae: 502160.6562\n",
            "Epoch 18/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 412403204096.0000 - mae: 507704.0625 - val_loss: 356516560896.0000 - val_mae: 495991.1875\n",
            "Epoch 19/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 405444984832.0000 - mae: 501358.7812 - val_loss: 349390798848.0000 - val_mae: 489216.8750\n",
            "Epoch 20/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 397918044160.0000 - mae: 494404.4688 - val_loss: 341733343232.0000 - val_mae: 481831.7500\n",
            "Epoch 21/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 389844205568.0000 - mae: 486836.0312 - val_loss: 333569753088.0000 - val_mae: 473833.0312\n",
            "Epoch 22/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 381250961408.0000 - mae: 478651.3438 - val_loss: 324931780608.0000 - val_mae: 465221.2188\n",
            "Epoch 23/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 372172488704.0000 - mae: 469851.9062 - val_loss: 315857010688.0000 - val_mae: 456000.4375\n",
            "Epoch 24/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 362648240128.0000 - mae: 460443.5000 - val_loss: 306388369408.0000 - val_mae: 446178.5625\n",
            "Epoch 25/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 352723599360.0000 - mae: 450440.1250 - val_loss: 296573960192.0000 - val_mae: 435767.0938\n",
            "Epoch 26/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 342449061888.0000 - mae: 439850.8125 - val_loss: 286466572288.0000 - val_mae: 424781.1250\n",
            "Epoch 27/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 331879579648.0000 - mae: 428693.0938 - val_loss: 276122828800.0000 - val_mae: 413240.0000\n",
            "Epoch 28/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 321074397184.0000 - mae: 416997.6250 - val_loss: 265603072000.0000 - val_mae: 401210.0938\n",
            "Epoch 29/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 310095970304.0000 - mae: 404825.5938 - val_loss: 254970183680.0000 - val_mae: 388725.0312\n",
            "Epoch 30/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 299009605632.0000 - mae: 392206.4375 - val_loss: 244289273856.0000 - val_mae: 375792.2500\n",
            "Epoch 31/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 287882346496.0000 - mae: 379175.5938 - val_loss: 233626304512.0000 - val_mae: 362488.2500\n",
            "Epoch 32/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 276782252032.0000 - mae: 365798.6562 - val_loss: 223047548928.0000 - val_mae: 348877.5938\n",
            "Epoch 33/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 265777397760.0000 - mae: 352109.1562 - val_loss: 212618608640.0000 - val_mae: 335071.3125\n",
            "Epoch 34/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 254935040000.0000 - mae: 338215.6250 - val_loss: 202403348480.0000 - val_mae: 321309.5938\n",
            "Epoch 35/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 244320321536.0000 - mae: 324354.4375 - val_loss: 192462848000.0000 - val_mae: 307612.6875\n",
            "Epoch 36/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 233995534336.0000 - mae: 310767.6562 - val_loss: 182854467584.0000 - val_mae: 294349.2812\n",
            "Epoch 37/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 224018907136.0000 - mae: 297592.1250 - val_loss: 173630881792.0000 - val_mae: 281786.4062\n",
            "Epoch 38/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 214443556864.0000 - mae: 284979.3750 - val_loss: 164839030784.0000 - val_mae: 270017.7500\n",
            "Epoch 39/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 205316718592.0000 - mae: 273074.4062 - val_loss: 156519268352.0000 - val_mae: 259050.9375\n",
            "Epoch 40/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 196678631424.0000 - mae: 261889.4219 - val_loss: 148704706560.0000 - val_mae: 248961.0000\n",
            "Epoch 41/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 188561981440.0000 - mae: 251983.7500 - val_loss: 141420478464.0000 - val_mae: 239561.6562\n",
            "Epoch 42/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 180991361024.0000 - mae: 242936.1562 - val_loss: 134683475968.0000 - val_mae: 231125.1719\n",
            "Epoch 43/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 173982662656.0000 - mae: 234846.8906 - val_loss: 128502095872.0000 - val_mae: 223778.9375\n",
            "Epoch 44/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 167543324672.0000 - mae: 227731.0781 - val_loss: 122876420096.0000 - val_mae: 217295.5156\n",
            "Epoch 45/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 161672134656.0000 - mae: 221381.2969 - val_loss: 117798494208.0000 - val_mae: 211535.0156\n",
            "Epoch 46/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 156360114176.0000 - mae: 215922.4688 - val_loss: 113253220352.0000 - val_mae: 206565.6719\n",
            "Epoch 47/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 151590879232.0000 - mae: 211281.1250 - val_loss: 109218955264.0000 - val_mae: 202383.9531\n",
            "Epoch 48/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 147341869056.0000 - mae: 207547.5469 - val_loss: 105668419584.0000 - val_mae: 198929.3438\n",
            "Epoch 49/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 143584804864.0000 - mae: 204548.0469 - val_loss: 102569762816.0000 - val_mae: 196087.5938\n",
            "Epoch 50/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140287066112.0000 - mae: 202156.5312 - val_loss: 99887243264.0000 - val_mae: 193902.3281\n",
            "Epoch 51/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 137411985408.0000 - mae: 200445.5156 - val_loss: 97581907968.0000 - val_mae: 192349.6250\n",
            "Epoch 52/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 134920396800.0000 - mae: 199182.2969 - val_loss: 95614951424.0000 - val_mae: 191209.0156\n",
            "Epoch 53/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132773306368.0000 - mae: 198355.3906 - val_loss: 93947158528.0000 - val_mae: 190379.6250\n",
            "Epoch 54/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 130931490816.0000 - mae: 197902.2500 - val_loss: 92540092416.0000 - val_mae: 189842.3281\n",
            "Epoch 55/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 129356611584.0000 - mae: 197697.1406 - val_loss: 91357003776.0000 - val_mae: 189540.2812\n",
            "Epoch 56/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 128012099584.0000 - mae: 197663.2188 - val_loss: 90363674624.0000 - val_mae: 189429.6250\n",
            "Epoch 57/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 126863892480.0000 - mae: 197740.8125 - val_loss: 89528713216.0000 - val_mae: 189498.7812\n",
            "Epoch 58/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 125880778752.0000 - mae: 197897.4219 - val_loss: 88824094720.0000 - val_mae: 189594.2656\n",
            "Epoch 59/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 125034799104.0000 - mae: 198061.9844 - val_loss: 88225300480.0000 - val_mae: 189761.8750\n",
            "Epoch 60/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 124301508608.0000 - mae: 198256.0781 - val_loss: 87711236096.0000 - val_mae: 189995.2812\n",
            "Epoch 61/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 123659698176.0000 - mae: 198452.6094 - val_loss: 87264100352.0000 - val_mae: 190229.7812\n",
            "Epoch 62/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 123091533824.0000 - mae: 198639.9531 - val_loss: 86869139456.0000 - val_mae: 190420.7031\n",
            "Epoch 63/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 122581991424.0000 - mae: 198807.6094 - val_loss: 86514245632.0000 - val_mae: 190621.4375\n",
            "Epoch 64/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 122118815744.0000 - mae: 198942.7812 - val_loss: 86189776896.0000 - val_mae: 190792.5156\n",
            "Epoch 65/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 121691996160.0000 - mae: 199050.9219 - val_loss: 85888081920.0000 - val_mae: 190924.6719\n",
            "Epoch 66/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 121293627392.0000 - mae: 199113.4375 - val_loss: 85603287040.0000 - val_mae: 191008.3750\n",
            "Epoch 67/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120917630976.0000 - mae: 199134.0625 - val_loss: 85330993152.0000 - val_mae: 191037.2031\n",
            "Epoch 68/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120559017984.0000 - mae: 199109.2188 - val_loss: 85067825152.0000 - val_mae: 191013.5469\n",
            "Epoch 69/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120214003712.0000 - mae: 199036.8281 - val_loss: 84811300864.0000 - val_mae: 190955.7656\n",
            "Epoch 70/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119879548928.0000 - mae: 198920.9062 - val_loss: 84559495168.0000 - val_mae: 190860.0000\n",
            "Epoch 71/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119553277952.0000 - mae: 198759.6875 - val_loss: 84311023616.0000 - val_mae: 190725.5469\n",
            "Epoch 72/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119233503232.0000 - mae: 198559.2969 - val_loss: 84064985088.0000 - val_mae: 190555.7188\n",
            "Epoch 73/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 118918832128.0000 - mae: 198326.9062 - val_loss: 83820658688.0000 - val_mae: 190355.3750\n",
            "Epoch 74/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 118608281600.0000 - mae: 198067.4062 - val_loss: 83577675776.0000 - val_mae: 190133.7969\n",
            "Epoch 75/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 118301073408.0000 - mae: 197783.8594 - val_loss: 83335659520.0000 - val_mae: 189889.1719\n",
            "Epoch 76/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117996609536.0000 - mae: 197478.1406 - val_loss: 83094446080.0000 - val_mae: 189629.0625\n",
            "Epoch 77/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117694398464.0000 - mae: 197154.2188 - val_loss: 82853863424.0000 - val_mae: 189354.5469\n",
            "Epoch 78/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117394079744.0000 - mae: 196819.3750 - val_loss: 82613813248.0000 - val_mae: 189067.6094\n",
            "Epoch 79/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117095317504.0000 - mae: 196473.1406 - val_loss: 82374238208.0000 - val_mae: 188768.4844\n",
            "Epoch 80/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116797857792.0000 - mae: 196114.1562 - val_loss: 82135056384.0000 - val_mae: 188458.8281\n",
            "Epoch 81/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116501504000.0000 - mae: 195744.5781 - val_loss: 81896275968.0000 - val_mae: 188139.3750\n",
            "Epoch 82/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116206067712.0000 - mae: 195366.0312 - val_loss: 81657815040.0000 - val_mae: 187811.2344\n",
            "Epoch 83/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 115911417856.0000 - mae: 194979.5625 - val_loss: 81419632640.0000 - val_mae: 187477.0000\n",
            "Epoch 84/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 115617382400.0000 - mae: 194586.3438 - val_loss: 81181679616.0000 - val_mae: 187137.6094\n",
            "Epoch 85/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 115323830272.0000 - mae: 194188.4062 - val_loss: 80943915008.0000 - val_mae: 186795.3438\n",
            "Epoch 86/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 115030679552.0000 - mae: 193785.7812 - val_loss: 80706330624.0000 - val_mae: 186455.6562\n",
            "Epoch 87/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 114737799168.0000 - mae: 193379.2031 - val_loss: 80468893696.0000 - val_mae: 186111.9844\n",
            "Epoch 88/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 114445131776.0000 - mae: 192969.0938 - val_loss: 80231522304.0000 - val_mae: 185763.7969\n",
            "Epoch 89/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 114152562688.0000 - mae: 192556.6719 - val_loss: 79994216448.0000 - val_mae: 185412.1094\n",
            "Epoch 90/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 113860026368.0000 - mae: 192141.6562 - val_loss: 79757000704.0000 - val_mae: 185058.2969\n",
            "Epoch 91/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 113567555584.0000 - mae: 191726.0469 - val_loss: 79519948800.0000 - val_mae: 184704.0000\n",
            "Epoch 92/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 113275174912.0000 - mae: 191308.7188 - val_loss: 79282880512.0000 - val_mae: 184346.8750\n",
            "Epoch 93/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 112982704128.0000 - mae: 190889.2656 - val_loss: 79045869568.0000 - val_mae: 183988.0469\n",
            "Epoch 94/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 112690257920.0000 - mae: 190468.2188 - val_loss: 78808858624.0000 - val_mae: 183629.3750\n",
            "Epoch 95/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112397705216.0000 - mae: 190045.1875 - val_loss: 78571773952.0000 - val_mae: 183275.0000\n",
            "Epoch 96/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 112105029632.0000 - mae: 189620.3125 - val_loss: 78334517248.0000 - val_mae: 182917.1719\n",
            "Epoch 97/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111812083712.0000 - mae: 189191.5938 - val_loss: 78097113088.0000 - val_mae: 182556.2188\n",
            "Epoch 98/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111518859264.0000 - mae: 188760.5625 - val_loss: 77859520512.0000 - val_mae: 182196.3281\n",
            "Epoch 99/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111225323520.0000 - mae: 188326.9844 - val_loss: 77621747712.0000 - val_mae: 181834.9844\n",
            "Epoch 100/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 110931451904.0000 - mae: 187892.1875 - val_loss: 77383811072.0000 - val_mae: 181472.4844\n",
            "Epoch 101/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 110637244416.0000 - mae: 187455.4688 - val_loss: 77145677824.0000 - val_mae: 181109.4062\n",
            "Epoch 102/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 110342643712.0000 - mae: 187016.9844 - val_loss: 76907421696.0000 - val_mae: 180745.7656\n",
            "Epoch 103/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 110047682560.0000 - mae: 186576.1094 - val_loss: 76669001728.0000 - val_mae: 180379.5156\n",
            "Epoch 104/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 109752344576.0000 - mae: 186132.3750 - val_loss: 76430344192.0000 - val_mae: 180010.4688\n",
            "Epoch 105/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 109456613376.0000 - mae: 185686.5312 - val_loss: 76191547392.0000 - val_mae: 179639.9688\n",
            "Epoch 106/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 109160546304.0000 - mae: 185239.0781 - val_loss: 75952570368.0000 - val_mae: 179270.3281\n",
            "Epoch 107/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108864102400.0000 - mae: 184789.9688 - val_loss: 75713511424.0000 - val_mae: 178899.8750\n",
            "Epoch 108/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108567306240.0000 - mae: 184339.2812 - val_loss: 75474190336.0000 - val_mae: 178526.2656\n",
            "Epoch 109/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108270116864.0000 - mae: 183885.6719 - val_loss: 75234648064.0000 - val_mae: 178149.7031\n",
            "Epoch 110/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107972550656.0000 - mae: 183429.3438 - val_loss: 74994851840.0000 - val_mae: 177772.0000\n",
            "Epoch 111/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107674574848.0000 - mae: 182970.1250 - val_loss: 74754826240.0000 - val_mae: 177391.0938\n",
            "Epoch 112/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107376164864.0000 - mae: 182507.7500 - val_loss: 74514554880.0000 - val_mae: 177007.0781\n",
            "Epoch 113/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107077369856.0000 - mae: 182042.6250 - val_loss: 74274045952.0000 - val_mae: 176619.9375\n",
            "Epoch 114/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106778157056.0000 - mae: 181574.8281 - val_loss: 74033315840.0000 - val_mae: 176231.4688\n",
            "Epoch 115/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106478526464.0000 - mae: 181105.0312 - val_loss: 73792364544.0000 - val_mae: 175841.3438\n",
            "Epoch 116/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106178551808.0000 - mae: 180634.2812 - val_loss: 73551216640.0000 - val_mae: 175448.6719\n",
            "Epoch 117/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 105878233088.0000 - mae: 180163.7656 - val_loss: 73309847552.0000 - val_mae: 175052.6719\n",
            "Epoch 118/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 105577553920.0000 - mae: 179689.8438 - val_loss: 73068265472.0000 - val_mae: 174653.3906\n",
            "Epoch 119/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 105276489728.0000 - mae: 179214.1406 - val_loss: 72826511360.0000 - val_mae: 174251.7188\n",
            "Epoch 120/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 104975081472.0000 - mae: 178736.9219 - val_loss: 72584650752.0000 - val_mae: 173847.0312\n",
            "Epoch 121/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104673312768.0000 - mae: 178258.2188 - val_loss: 72342626304.0000 - val_mae: 173439.2500\n",
            "Epoch 122/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 104371232768.0000 - mae: 177776.3750 - val_loss: 72100503552.0000 - val_mae: 173028.2812\n",
            "Epoch 123/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 104068841472.0000 - mae: 177291.4062 - val_loss: 71858290688.0000 - val_mae: 172614.2188\n",
            "Epoch 124/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103766130688.0000 - mae: 176804.7969 - val_loss: 71615971328.0000 - val_mae: 172197.0156\n",
            "Epoch 125/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103463157760.0000 - mae: 176316.7344 - val_loss: 71373561856.0000 - val_mae: 171781.1562\n",
            "Epoch 126/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103159906304.0000 - mae: 175829.5938 - val_loss: 71131062272.0000 - val_mae: 171362.7969\n",
            "Epoch 127/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 102856417280.0000 - mae: 175341.4375 - val_loss: 70888505344.0000 - val_mae: 170941.5156\n",
            "Epoch 128/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 102552698880.0000 - mae: 174851.3281 - val_loss: 70645891072.0000 - val_mae: 170519.4688\n",
            "Epoch 129/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 102248792064.0000 - mae: 174360.1250 - val_loss: 70403252224.0000 - val_mae: 170094.9688\n",
            "Epoch 130/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101944688640.0000 - mae: 173866.9688 - val_loss: 70160605184.0000 - val_mae: 169668.4375\n",
            "Epoch 131/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101640454144.0000 - mae: 173374.9375 - val_loss: 69917974528.0000 - val_mae: 169238.8281\n",
            "Epoch 132/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101336080384.0000 - mae: 172883.7812 - val_loss: 69675376640.0000 - val_mae: 168806.1562\n",
            "Epoch 133/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101031600128.0000 - mae: 172391.7188 - val_loss: 69432836096.0000 - val_mae: 168370.3750\n",
            "Epoch 134/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100727029760.0000 - mae: 171898.0625 - val_loss: 69190361088.0000 - val_mae: 167932.3906\n",
            "Epoch 135/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 100422426624.0000 - mae: 171402.7188 - val_loss: 68948008960.0000 - val_mae: 167496.3594\n",
            "Epoch 136/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 100117798912.0000 - mae: 170905.6250 - val_loss: 68705759232.0000 - val_mae: 167064.2344\n",
            "Epoch 137/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99813179392.0000 - mae: 170408.5625 - val_loss: 68463669248.0000 - val_mae: 166635.8906\n",
            "Epoch 138/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99508576256.0000 - mae: 169909.8750 - val_loss: 68221755392.0000 - val_mae: 166205.6094\n",
            "Epoch 139/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99204079616.0000 - mae: 169408.1406 - val_loss: 67980038144.0000 - val_mae: 165772.6719\n",
            "Epoch 140/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98899656704.0000 - mae: 168903.5312 - val_loss: 67738546176.0000 - val_mae: 165342.7812\n",
            "Epoch 141/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98595373056.0000 - mae: 168397.6250 - val_loss: 67497332736.0000 - val_mae: 164911.4219\n",
            "Epoch 142/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98291261440.0000 - mae: 167890.0938 - val_loss: 67256377344.0000 - val_mae: 164477.1562\n",
            "Epoch 143/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 97987354624.0000 - mae: 167380.6875 - val_loss: 67015667712.0000 - val_mae: 164037.9375\n",
            "Epoch 144/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97683734528.0000 - mae: 166867.5781 - val_loss: 66775252992.0000 - val_mae: 163599.4844\n",
            "Epoch 145/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97379999744.0000 - mae: 166357.5781 - val_loss: 66535063552.0000 - val_mae: 163156.5000\n",
            "Epoch 146/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97076600832.0000 - mae: 165844.7812 - val_loss: 66295107584.0000 - val_mae: 162715.4219\n",
            "Epoch 147/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96773324800.0000 - mae: 165330.9375 - val_loss: 66055409664.0000 - val_mae: 162274.6719\n",
            "Epoch 148/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96470220800.0000 - mae: 164814.8594 - val_loss: 65816039424.0000 - val_mae: 161830.6562\n",
            "Epoch 149/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96167419904.0000 - mae: 164295.6562 - val_loss: 65577029632.0000 - val_mae: 161383.6875\n",
            "Epoch 150/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95864905728.0000 - mae: 163773.6094 - val_loss: 65338474496.0000 - val_mae: 160934.1094\n",
            "Epoch 151/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95562792960.0000 - mae: 163250.5781 - val_loss: 65100406784.0000 - val_mae: 160481.6562\n",
            "Epoch 152/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95261138944.0000 - mae: 162727.3281 - val_loss: 64862859264.0000 - val_mae: 160030.3281\n",
            "Epoch 153/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94959984640.0000 - mae: 162201.9062 - val_loss: 64625913856.0000 - val_mae: 159577.0156\n",
            "Epoch 154/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94659395584.0000 - mae: 161677.5000 - val_loss: 64389582848.0000 - val_mae: 159120.9062\n",
            "Epoch 155/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94359412736.0000 - mae: 161154.1250 - val_loss: 64153915392.0000 - val_mae: 158664.8438\n",
            "Epoch 156/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94060126208.0000 - mae: 160630.9844 - val_loss: 63918940160.0000 - val_mae: 158210.1562\n",
            "Epoch 157/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93761536000.0000 - mae: 160110.4844 - val_loss: 63684726784.0000 - val_mae: 157758.9844\n",
            "Epoch 158/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93463691264.0000 - mae: 159589.3594 - val_loss: 63451295744.0000 - val_mae: 157306.2031\n",
            "Epoch 159/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93166698496.0000 - mae: 159073.4688 - val_loss: 63218675712.0000 - val_mae: 156855.0938\n",
            "Epoch 160/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92870549504.0000 - mae: 158562.6094 - val_loss: 62986924032.0000 - val_mae: 156409.3281\n",
            "Epoch 161/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92575293440.0000 - mae: 158055.9844 - val_loss: 62756069376.0000 - val_mae: 155967.7969\n",
            "Epoch 162/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92281012224.0000 - mae: 157553.2969 - val_loss: 62526148608.0000 - val_mae: 155531.0625\n",
            "Epoch 163/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91987755008.0000 - mae: 157054.2188 - val_loss: 62297210880.0000 - val_mae: 155094.2656\n",
            "Epoch 164/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91695521792.0000 - mae: 156561.0938 - val_loss: 62069280768.0000 - val_mae: 154655.0312\n",
            "Epoch 165/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 91404386304.0000 - mae: 156075.7969 - val_loss: 61842407424.0000 - val_mae: 154214.3750\n",
            "Epoch 166/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91114414080.0000 - mae: 155597.1562 - val_loss: 61616599040.0000 - val_mae: 153771.3438\n",
            "Epoch 167/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90825596928.0000 - mae: 155122.6406 - val_loss: 61391937536.0000 - val_mae: 153329.2344\n",
            "Epoch 168/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90538065920.0000 - mae: 154651.0312 - val_loss: 61168431104.0000 - val_mae: 152888.5156\n",
            "Epoch 169/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90251878400.0000 - mae: 154183.5000 - val_loss: 60946255872.0000 - val_mae: 152456.9531\n",
            "Epoch 170/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89967345664.0000 - mae: 153722.6719 - val_loss: 60725317632.0000 - val_mae: 152023.8125\n",
            "Epoch 171/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89684303872.0000 - mae: 153264.9219 - val_loss: 60505661440.0000 - val_mae: 151594.6719\n",
            "Epoch 172/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89402785792.0000 - mae: 152812.2812 - val_loss: 60287336448.0000 - val_mae: 151166.0156\n",
            "Epoch 173/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89122807808.0000 - mae: 152369.7969 - val_loss: 60070375424.0000 - val_mae: 150740.7969\n",
            "Epoch 174/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88844419072.0000 - mae: 151930.6562 - val_loss: 59854802944.0000 - val_mae: 150314.1562\n",
            "Epoch 175/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88567644160.0000 - mae: 151496.7969 - val_loss: 59640668160.0000 - val_mae: 149891.3438\n",
            "Epoch 176/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88292515840.0000 - mae: 151065.0469 - val_loss: 59427991552.0000 - val_mae: 149471.9062\n",
            "Epoch 177/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88019738624.0000 - mae: 150642.5312 - val_loss: 59216928768.0000 - val_mae: 149061.5469\n",
            "Epoch 178/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87748468736.0000 - mae: 150227.3438 - val_loss: 59007201280.0000 - val_mae: 148659.4531\n",
            "Epoch 179/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87479148544.0000 - mae: 149814.5000 - val_loss: 58798874624.0000 - val_mae: 148272.6406\n",
            "Epoch 180/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87210876928.0000 - mae: 149412.0625 - val_loss: 58592038912.0000 - val_mae: 147892.0625\n",
            "Epoch 181/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86944817152.0000 - mae: 149005.9688 - val_loss: 58386739200.0000 - val_mae: 147512.4688\n",
            "Epoch 182/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86680616960.0000 - mae: 148601.6250 - val_loss: 58183163904.0000 - val_mae: 147138.0156\n",
            "Epoch 183/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86418227200.0000 - mae: 148202.7969 - val_loss: 57981022208.0000 - val_mae: 146768.6406\n",
            "Epoch 184/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86157836288.0000 - mae: 147805.0781 - val_loss: 57780645888.0000 - val_mae: 146413.0625\n",
            "Epoch 185/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85899280384.0000 - mae: 147415.8281 - val_loss: 57581895680.0000 - val_mae: 146056.7031\n",
            "Epoch 186/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85642903552.0000 - mae: 147028.8906 - val_loss: 57384935424.0000 - val_mae: 145709.3906\n",
            "Epoch 187/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85388402688.0000 - mae: 146650.5000 - val_loss: 57189699584.0000 - val_mae: 145365.5312\n",
            "Epoch 188/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85135974400.0000 - mae: 146273.4531 - val_loss: 56996167680.0000 - val_mae: 145032.6562\n",
            "Epoch 189/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84885807104.0000 - mae: 145901.3594 - val_loss: 56804511744.0000 - val_mae: 144707.2969\n",
            "Epoch 190/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84637548544.0000 - mae: 145537.1094 - val_loss: 56614572032.0000 - val_mae: 144389.4062\n",
            "Epoch 191/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84391747584.0000 - mae: 145175.9688 - val_loss: 56426610688.0000 - val_mae: 144087.7031\n",
            "Epoch 192/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84147748864.0000 - mae: 144825.4688 - val_loss: 56240451584.0000 - val_mae: 143794.6875\n",
            "Epoch 193/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83906060288.0000 - mae: 144478.6094 - val_loss: 56056119296.0000 - val_mae: 143494.9062\n",
            "Epoch 194/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83666747392.0000 - mae: 144134.6719 - val_loss: 55873622016.0000 - val_mae: 143206.5938\n",
            "Epoch 195/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83429646336.0000 - mae: 143804.0625 - val_loss: 55693062144.0000 - val_mae: 142923.3750\n",
            "Epoch 196/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83194691584.0000 - mae: 143483.7812 - val_loss: 55514378240.0000 - val_mae: 142637.5000\n",
            "Epoch 197/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82962145280.0000 - mae: 143169.4844 - val_loss: 55337590784.0000 - val_mae: 142357.0781\n",
            "Epoch 198/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82731737088.0000 - mae: 142868.6094 - val_loss: 55162695680.0000 - val_mae: 142074.5938\n",
            "Epoch 199/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82503811072.0000 - mae: 142574.9375 - val_loss: 54989713408.0000 - val_mae: 141800.6875\n",
            "Epoch 200/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82277982208.0000 - mae: 142297.4844 - val_loss: 54818648064.0000 - val_mae: 141527.3750\n",
            "Epoch 201/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82054610944.0000 - mae: 142024.5312 - val_loss: 54649483264.0000 - val_mae: 141265.5156\n",
            "Epoch 202/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81833377792.0000 - mae: 141765.2344 - val_loss: 54482264064.0000 - val_mae: 141007.4531\n",
            "Epoch 203/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81614462976.0000 - mae: 141512.0625 - val_loss: 54316916736.0000 - val_mae: 140748.9688\n",
            "Epoch 204/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81398054912.0000 - mae: 141257.6094 - val_loss: 54153478144.0000 - val_mae: 140498.8750\n",
            "Epoch 205/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81183711232.0000 - mae: 141012.1875 - val_loss: 53991907328.0000 - val_mae: 140246.2344\n",
            "Epoch 206/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80971890688.0000 - mae: 140768.7344 - val_loss: 53832278016.0000 - val_mae: 140000.6406\n",
            "Epoch 207/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80762150912.0000 - mae: 140537.8594 - val_loss: 53674512384.0000 - val_mae: 139761.8281\n",
            "Epoch 208/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80554745856.0000 - mae: 140313.3125 - val_loss: 53518663680.0000 - val_mae: 139534.0469\n",
            "Epoch 209/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80349634560.0000 - mae: 140096.7500 - val_loss: 53364621312.0000 - val_mae: 139319.4219\n",
            "Epoch 210/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80146743296.0000 - mae: 139890.7969 - val_loss: 53212450816.0000 - val_mae: 139101.9219\n",
            "Epoch 211/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79946358784.0000 - mae: 139687.3125 - val_loss: 53062098944.0000 - val_mae: 138890.2344\n",
            "Epoch 212/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79747915776.0000 - mae: 139492.0312 - val_loss: 52913594368.0000 - val_mae: 138679.2031\n",
            "Epoch 213/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79551954944.0000 - mae: 139297.1094 - val_loss: 52766879744.0000 - val_mae: 138476.3906\n",
            "Epoch 214/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79357960192.0000 - mae: 139110.7812 - val_loss: 52621971456.0000 - val_mae: 138278.0938\n",
            "Epoch 215/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79166210048.0000 - mae: 138927.2812 - val_loss: 52478857216.0000 - val_mae: 138086.2656\n",
            "Epoch 216/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78976655360.0000 - mae: 138747.2188 - val_loss: 52337459200.0000 - val_mae: 137898.6719\n",
            "Epoch 217/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78789255168.0000 - mae: 138573.7031 - val_loss: 52197855232.0000 - val_mae: 137711.1406\n",
            "Epoch 218/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78603993088.0000 - mae: 138402.5781 - val_loss: 52059975680.0000 - val_mae: 137528.7969\n",
            "Epoch 219/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78420860928.0000 - mae: 138237.4688 - val_loss: 51923726336.0000 - val_mae: 137348.3906\n",
            "Epoch 220/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78239784960.0000 - mae: 138076.2500 - val_loss: 51789172736.0000 - val_mae: 137170.3438\n",
            "Epoch 221/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78060781568.0000 - mae: 137917.6094 - val_loss: 51656335360.0000 - val_mae: 136995.7969\n",
            "Epoch 222/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77883858944.0000 - mae: 137761.7812 - val_loss: 51525074944.0000 - val_mae: 136830.6719\n",
            "Epoch 223/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77708902400.0000 - mae: 137611.8750 - val_loss: 51395506176.0000 - val_mae: 136670.7500\n",
            "Epoch 224/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77535985664.0000 - mae: 137469.0625 - val_loss: 51267457024.0000 - val_mae: 136517.9844\n",
            "Epoch 225/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77364961280.0000 - mae: 137328.1562 - val_loss: 51140964352.0000 - val_mae: 136367.2500\n",
            "Epoch 226/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77195878400.0000 - mae: 137192.7031 - val_loss: 51016052736.0000 - val_mae: 136217.1875\n",
            "Epoch 227/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77028933632.0000 - mae: 137065.5938 - val_loss: 50892623872.0000 - val_mae: 136069.5625\n",
            "Epoch 228/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76863594496.0000 - mae: 136948.2500 - val_loss: 50770694144.0000 - val_mae: 135924.4219\n",
            "Epoch 229/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76700106752.0000 - mae: 136832.4062 - val_loss: 50650267648.0000 - val_mae: 135778.1719\n",
            "Epoch 230/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76538691584.0000 - mae: 136719.1562 - val_loss: 50531254272.0000 - val_mae: 135637.6562\n",
            "Epoch 231/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76378832896.0000 - mae: 136608.9844 - val_loss: 50413674496.0000 - val_mae: 135497.1875\n",
            "Epoch 232/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76220768256.0000 - mae: 136499.5312 - val_loss: 50297450496.0000 - val_mae: 135356.6562\n",
            "Epoch 233/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76064448512.0000 - mae: 136390.7812 - val_loss: 50182619136.0000 - val_mae: 135215.5312\n",
            "Epoch 234/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75909890048.0000 - mae: 136286.7969 - val_loss: 50069139456.0000 - val_mae: 135073.9844\n",
            "Epoch 235/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75757027328.0000 - mae: 136187.6562 - val_loss: 49956990976.0000 - val_mae: 134932.4219\n",
            "Epoch 236/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75605852160.0000 - mae: 136091.5312 - val_loss: 49846157312.0000 - val_mae: 134791.2031\n",
            "Epoch 237/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75456290816.0000 - mae: 135997.5781 - val_loss: 49736785920.0000 - val_mae: 134647.7031\n",
            "Epoch 238/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75308425216.0000 - mae: 135902.5625 - val_loss: 49628635136.0000 - val_mae: 134506.4688\n",
            "Epoch 239/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75162025984.0000 - mae: 135813.9688 - val_loss: 49521696768.0000 - val_mae: 134367.3438\n",
            "Epoch 240/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75017150464.0000 - mae: 135726.4531 - val_loss: 49415950336.0000 - val_mae: 134229.3750\n",
            "Epoch 241/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74873774080.0000 - mae: 135643.2812 - val_loss: 49311326208.0000 - val_mae: 134094.7812\n",
            "Epoch 242/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74731880448.0000 - mae: 135565.5000 - val_loss: 49207865344.0000 - val_mae: 133965.8906\n",
            "Epoch 243/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74591485952.0000 - mae: 135490.1562 - val_loss: 49105485824.0000 - val_mae: 133840.5156\n",
            "Epoch 244/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74452516864.0000 - mae: 135417.2656 - val_loss: 49004179456.0000 - val_mae: 133719.0938\n",
            "Epoch 245/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74315120640.0000 - mae: 135344.3125 - val_loss: 48904073216.0000 - val_mae: 133598.9219\n",
            "Epoch 246/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74179108864.0000 - mae: 135274.2344 - val_loss: 48804966400.0000 - val_mae: 133480.7344\n",
            "Epoch 247/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74044506112.0000 - mae: 135203.9375 - val_loss: 48706924544.0000 - val_mae: 133369.2656\n",
            "Epoch 248/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73911353344.0000 - mae: 135132.3594 - val_loss: 48609964032.0000 - val_mae: 133262.5312\n",
            "Epoch 249/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73779535872.0000 - mae: 135063.5156 - val_loss: 48513998848.0000 - val_mae: 133160.8438\n",
            "Epoch 250/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73649029120.0000 - mae: 134995.2188 - val_loss: 48418902016.0000 - val_mae: 133060.7812\n",
            "Epoch 251/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73519955968.0000 - mae: 134926.8438 - val_loss: 48324689920.0000 - val_mae: 132958.7344\n",
            "Epoch 252/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73392136192.0000 - mae: 134861.8906 - val_loss: 48231145472.0000 - val_mae: 132856.1094\n",
            "Epoch 253/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73265528832.0000 - mae: 134798.2656 - val_loss: 48138235904.0000 - val_mae: 132753.7969\n",
            "Epoch 254/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73140215808.0000 - mae: 134734.9844 - val_loss: 48046280704.0000 - val_mae: 132655.3438\n",
            "Epoch 255/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73016156160.0000 - mae: 134672.6250 - val_loss: 47955255296.0000 - val_mae: 132561.6875\n",
            "Epoch 256/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72893333504.0000 - mae: 134611.5625 - val_loss: 47865151488.0000 - val_mae: 132468.8281\n",
            "Epoch 257/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72771715072.0000 - mae: 134549.9219 - val_loss: 47775956992.0000 - val_mae: 132375.9375\n",
            "Epoch 258/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72651259904.0000 - mae: 134488.4062 - val_loss: 47687630848.0000 - val_mae: 132283.1250\n",
            "Epoch 259/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72531976192.0000 - mae: 134427.4688 - val_loss: 47600181248.0000 - val_mae: 132190.2188\n",
            "Epoch 260/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72413814784.0000 - mae: 134366.9844 - val_loss: 47513575424.0000 - val_mae: 132099.5312\n",
            "Epoch 261/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72296767488.0000 - mae: 134308.6250 - val_loss: 47427805184.0000 - val_mae: 132009.1250\n",
            "Epoch 262/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72180809728.0000 - mae: 134251.2031 - val_loss: 47342911488.0000 - val_mae: 131921.3438\n",
            "Epoch 263/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72065982464.0000 - mae: 134192.0781 - val_loss: 47258755072.0000 - val_mae: 131837.6719\n",
            "Epoch 264/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71952121856.0000 - mae: 134136.0469 - val_loss: 47175417856.0000 - val_mae: 131754.3750\n",
            "Epoch 265/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71839358976.0000 - mae: 134080.2031 - val_loss: 47092817920.0000 - val_mae: 131670.7031\n",
            "Epoch 266/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71727570944.0000 - mae: 134028.3594 - val_loss: 47010942976.0000 - val_mae: 131587.0469\n",
            "Epoch 267/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71616823296.0000 - mae: 133976.4219 - val_loss: 46929788928.0000 - val_mae: 131503.8438\n",
            "Epoch 268/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71507075072.0000 - mae: 133925.0312 - val_loss: 46849384448.0000 - val_mae: 131420.9375\n",
            "Epoch 269/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71398367232.0000 - mae: 133873.6562 - val_loss: 46769717248.0000 - val_mae: 131338.3125\n",
            "Epoch 270/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71290634240.0000 - mae: 133823.3281 - val_loss: 46690762752.0000 - val_mae: 131258.0156\n",
            "Epoch 271/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71183867904.0000 - mae: 133773.9062 - val_loss: 46612520960.0000 - val_mae: 131177.3125\n",
            "Epoch 272/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71078043648.0000 - mae: 133723.7969 - val_loss: 46534955008.0000 - val_mae: 131096.0312\n",
            "Epoch 273/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70973153280.0000 - mae: 133673.5000 - val_loss: 46458081280.0000 - val_mae: 131014.6406\n",
            "Epoch 274/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70869164032.0000 - mae: 133623.4062 - val_loss: 46381846528.0000 - val_mae: 130934.0859\n",
            "Epoch 275/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70766092288.0000 - mae: 133573.7656 - val_loss: 46306271232.0000 - val_mae: 130854.8984\n",
            "Epoch 276/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70663872512.0000 - mae: 133524.8594 - val_loss: 46231343104.0000 - val_mae: 130776.8906\n",
            "Epoch 277/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70562537472.0000 - mae: 133475.1562 - val_loss: 46157029376.0000 - val_mae: 130698.5547\n",
            "Epoch 278/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70462054400.0000 - mae: 133424.6562 - val_loss: 46083334144.0000 - val_mae: 130622.7812\n",
            "Epoch 279/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70362406912.0000 - mae: 133373.2969 - val_loss: 46010302464.0000 - val_mae: 130550.1875\n",
            "Epoch 280/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70263603200.0000 - mae: 133321.0156 - val_loss: 45937868800.0000 - val_mae: 130478.3672\n",
            "Epoch 281/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70165577728.0000 - mae: 133268.5938 - val_loss: 45866086400.0000 - val_mae: 130409.6953\n",
            "Epoch 282/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70068355072.0000 - mae: 133215.8594 - val_loss: 45794856960.0000 - val_mae: 130344.3281\n",
            "Epoch 283/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69971869696.0000 - mae: 133162.9062 - val_loss: 45724172288.0000 - val_mae: 130279.9531\n",
            "Epoch 284/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69876121600.0000 - mae: 133109.4375 - val_loss: 45654024192.0000 - val_mae: 130215.0625\n",
            "Epoch 285/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69781110784.0000 - mae: 133055.6250 - val_loss: 45584416768.0000 - val_mae: 130150.2500\n",
            "Epoch 286/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69686837248.0000 - mae: 133002.1250 - val_loss: 45515337728.0000 - val_mae: 130084.7969\n",
            "Epoch 287/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69593300992.0000 - mae: 132948.6250 - val_loss: 45446787072.0000 - val_mae: 130019.1875\n",
            "Epoch 288/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69500502016.0000 - mae: 132895.4688 - val_loss: 45378785280.0000 - val_mae: 129953.2188\n",
            "Epoch 289/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69408399360.0000 - mae: 132842.7188 - val_loss: 45311340544.0000 - val_mae: 129886.9219\n",
            "Epoch 290/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69317009408.0000 - mae: 132789.9375 - val_loss: 45244383232.0000 - val_mae: 129820.1172\n",
            "Epoch 291/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69226315776.0000 - mae: 132738.2188 - val_loss: 45177929728.0000 - val_mae: 129752.6406\n",
            "Epoch 292/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69136310272.0000 - mae: 132687.6406 - val_loss: 45111963648.0000 - val_mae: 129685.1641\n",
            "Epoch 293/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69046984704.0000 - mae: 132637.5312 - val_loss: 45046521856.0000 - val_mae: 129617.3359\n",
            "Epoch 294/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68958322688.0000 - mae: 132588.4844 - val_loss: 44981608448.0000 - val_mae: 129548.9219\n",
            "Epoch 295/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68870316032.0000 - mae: 132539.6094 - val_loss: 44917153792.0000 - val_mae: 129479.8906\n",
            "Epoch 296/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68782956544.0000 - mae: 132492.6250 - val_loss: 44853161984.0000 - val_mae: 129410.2578\n",
            "Epoch 297/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68696244224.0000 - mae: 132445.9531 - val_loss: 44789624832.0000 - val_mae: 129340.2578\n",
            "Epoch 298/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68610154496.0000 - mae: 132398.7031 - val_loss: 44726530048.0000 - val_mae: 129274.0234\n",
            "Epoch 299/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68525035520.0000 - mae: 132353.8125 - val_loss: 44663123968.0000 - val_mae: 129215.5078\n",
            "Epoch 300/300\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68439883776.0000 - mae: 132307.9219 - val_loss: 44601061376.0000 - val_mae: 129156.4453\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=300,              # Maximum number of epochs\n",
        "                    batch_size=64,           # Size of mini-batches\n",
        "                    validation_split=0.2,    # Validation data split\n",
        "                    callbacks=[early_stopping])  # Include the EarlyStopping callback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "eZYIaccC38GL",
        "outputId": "0f66d953-a574-46b2-9702-44f5a60ae346"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TudTwW2g5I0P",
        "outputId": "c98ae9d6-6e18-4b67-e85b-befb0dd8bf02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180787068928.0000 - mae: 153784.1250\n",
            "Test MAE: 177758.921875\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE: {test_mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "9FwtDch063_s",
        "outputId": "b89d7967-b5d1-46d1-a233-1548723e708c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>...</th>\n",
              "      <th>statezip_WA 98178</th>\n",
              "      <th>statezip_WA 98188</th>\n",
              "      <th>statezip_WA 98198</th>\n",
              "      <th>statezip_WA 98199</th>\n",
              "      <th>statezip_WA 98288</th>\n",
              "      <th>statezip_WA 98354</th>\n",
              "      <th>house_age</th>\n",
              "      <th>years_since_renovation</th>\n",
              "      <th>has_basement</th>\n",
              "      <th>total_sqft</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3683</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.082764</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.089602</td>\n",
              "      <td>0.058091</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.061404</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.123766</td>\n",
              "      <td>0.006764</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.102876</td>\n",
              "      <td>0.145228</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.245614</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2584</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.195140</td>\n",
              "      <td>0.004465</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.228982</td>\n",
              "      <td>0.103734</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.006951</td>\n",
              "      <td>1</td>\n",
              "      <td>0.006459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.138952</td>\n",
              "      <td>0.006252</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.132743</td>\n",
              "      <td>0.130705</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.228070</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1844</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.102506</td>\n",
              "      <td>0.007561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.069690</td>\n",
              "      <td>0.149378</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.271930</td>\n",
              "      <td>0.002483</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1612</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.100987</td>\n",
              "      <td>0.007230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.120575</td>\n",
              "      <td>0.049793</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.587719</td>\n",
              "      <td>0.000993</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.118451</td>\n",
              "      <td>0.005106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.172566</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.640351</td>\n",
              "      <td>0.022344</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4350</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.061503</td>\n",
              "      <td>0.006665</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.089602</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.192982</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3027</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.151860</td>\n",
              "      <td>0.008798</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.221239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.010253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3455</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.143508</td>\n",
              "      <td>0.006112</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.209071</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007471</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>920 rows × 138 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
              "3683         3          2     0.082764  0.000908     0.5         0.0  0.00   \n",
              "4411         5          2     0.123766  0.006764     0.0         0.0  0.00   \n",
              "2584         3          3     0.195140  0.004465     1.0         0.0  0.75   \n",
              "69           3          2     0.138952  0.006252     0.0         0.0  0.00   \n",
              "1844         3          2     0.102506  0.007561     0.0         0.0  0.00   \n",
              "...        ...        ...          ...       ...     ...         ...   ...   \n",
              "1612         3          1     0.100987  0.007230     0.0         0.0  0.00   \n",
              "1068         5          2     0.118451  0.005106     0.0         0.0  0.00   \n",
              "4350         3          2     0.061503  0.006665     0.0         0.0  0.00   \n",
              "3027         4          2     0.151860  0.008798     0.5         0.0  0.00   \n",
              "3455         4          2     0.143508  0.006112     0.5         0.0  0.00   \n",
              "\n",
              "      condition  sqft_above  sqft_basement  ...  statezip_WA 98178  \\\n",
              "3683       0.50    0.089602       0.058091  ...              False   \n",
              "4411       0.75    0.102876       0.145228  ...              False   \n",
              "2584       0.75    0.228982       0.103734  ...              False   \n",
              "69         1.00    0.132743       0.130705  ...              False   \n",
              "1844       0.50    0.069690       0.149378  ...              False   \n",
              "...         ...         ...            ...  ...                ...   \n",
              "1612       0.50    0.120575       0.049793  ...              False   \n",
              "1068       0.50    0.172566       0.000000  ...              False   \n",
              "4350       0.75    0.089602       0.000000  ...              False   \n",
              "3027       1.00    0.221239       0.000000  ...              False   \n",
              "3455       0.75    0.209071       0.000000  ...              False   \n",
              "\n",
              "      statezip_WA 98188  statezip_WA 98198  statezip_WA 98199  \\\n",
              "3683              False              False              False   \n",
              "4411               True              False              False   \n",
              "2584              False              False              False   \n",
              "69                False              False              False   \n",
              "1844              False              False              False   \n",
              "...                 ...                ...                ...   \n",
              "1612              False              False               True   \n",
              "1068              False              False              False   \n",
              "4350              False              False              False   \n",
              "3027              False              False              False   \n",
              "3455              False              False              False   \n",
              "\n",
              "      statezip_WA 98288  statezip_WA 98354  house_age  years_since_renovation  \\\n",
              "3683              False              False   0.061404                1.000000   \n",
              "4411              False              False   0.245614                1.000000   \n",
              "2584              False              False   0.315789                0.006951   \n",
              "69                False              False   0.228070                1.000000   \n",
              "1844              False              False   0.271930                0.002483   \n",
              "...                 ...                ...        ...                     ...   \n",
              "1612              False              False   0.587719                0.000993   \n",
              "1068              False              False   0.640351                0.022344   \n",
              "4350              False              False   0.192982                1.000000   \n",
              "3027              False              False   0.421053                1.000000   \n",
              "3455              False              False   0.263158                1.000000   \n",
              "\n",
              "      has_basement  total_sqft  \n",
              "3683             1    0.001534  \n",
              "4411             1    0.007880  \n",
              "2584             1    0.006459  \n",
              "69               1    0.007554  \n",
              "1844             1    0.008414  \n",
              "...            ...         ...  \n",
              "1612             1    0.008066  \n",
              "1068             0    0.006160  \n",
              "4350             0    0.007018  \n",
              "3027             0    0.010253  \n",
              "3455             0    0.007471  \n",
              "\n",
              "[920 rows x 138 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "sCpCcUPE7PTi",
        "outputId": "cf8280b9-a59f-4b22-998b-882a661412c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "bedrooms                         3\n",
              "bathrooms                        2\n",
              "sqft_living               0.082764\n",
              "sqft_lot                  0.000908\n",
              "floors                         0.5\n",
              "                            ...   \n",
              "statezip_WA 98354            False\n",
              "house_age                 0.061404\n",
              "years_since_renovation         1.0\n",
              "has_basement                     1\n",
              "total_sqft                0.001534\n",
              "Name: 3683, Length: 138, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqxBZohV7fe2",
        "outputId": "367f923b-25ff-46eb-cb3b-a9ce5c5dbe1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3, 2, 0.08276385725132879, 0.0009081763818252948, 0.5, 0.0, 0.0,\n",
              "        0.5, 0.08960176991150443, 0.058091286307053944,\n",
              "        0.938596491228072, 0.0, 0.0, 0.5, 0.9666666666666667, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, True, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, True, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, 0.06140350877192982, 1.0, 1, 0.0015337352029410533]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.iloc[0].values.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "vsY9hoIs7sMR",
        "outputId": "457e319e-fe8f-4602-85cc-ba6c8a658108"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "bedrooms                         3\n",
              "bathrooms                        2\n",
              "sqft_living               0.082764\n",
              "sqft_lot                  0.000908\n",
              "floors                         0.5\n",
              "                            ...   \n",
              "statezip_WA 98354            False\n",
              "house_age                 0.061404\n",
              "years_since_renovation         1.0\n",
              "has_basement                     1\n",
              "total_sqft                0.001534\n",
              "Name: 3683, Length: 138, dtype: object"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9KZWcSf8GPG",
        "outputId": "3ae0bdb4-cf6f-47e9-ab0e-8077dcb21146"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n",
            "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_13776\\1030776324.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  house_df[col] = 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Single house data\n",
        "house = {\n",
        "    'date': '2023-08-31',\n",
        "    'bedrooms': 3,\n",
        "    'bathrooms': 2,\n",
        "    'sqft_living': 1800,\n",
        "    'sqft_lot': 10000,\n",
        "    'floors': 1,\n",
        "    'waterfront': 0,\n",
        "    'view': 0,\n",
        "    'condition': 3,\n",
        "    'sqft_above': 1800,\n",
        "    'sqft_basement': 0,\n",
        "    'yr_built': 2020,\n",
        "    'yr_renovated': 0,\n",
        "    'city': 'Seattle',\n",
        "    'statezip': 'WA 98125'\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "house_df = pd.DataFrame([house])\n",
        "\n",
        "# Preprocess the date\n",
        "house_df['date'] = pd.to_datetime(house_df['date'])\n",
        "house_df['year_sold'] = house_df['date'].dt.year\n",
        "house_df['month_sold'] = house_df['date'].dt.month\n",
        "house_df['day_sold'] = house_df['date'].dt.day\n",
        "\n",
        "# Feature engineering\n",
        "house_df['house_age'] = house_df['year_sold'] - house_df['yr_built']\n",
        "house_df['years_since_renovation'] = house_df['year_sold'] - house_df['yr_renovated']\n",
        "house_df['years_since_renovation'] = house_df['years_since_renovation'].apply(lambda x: x if x >= 0 else 0)\n",
        "house_df['total_sqft'] = house_df['sqft_living'] + house_df['sqft_lot']\n",
        "house_df['has_basement'] = house_df['sqft_basement'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "house_df = house_df.drop(columns=['date', 'yr_built', 'yr_renovated'])\n",
        "\n",
        "# One-hot encoding for categorical features\n",
        "house_df = pd.get_dummies(house_df, columns=['city', 'statezip'], drop_first=True)\n",
        "\n",
        "# Ensure the single input has the same features as the training data\n",
        "# Assuming X_train was your original training data after preprocessing\n",
        "missing_cols = set(X_train.columns) - set(house_df.columns)\n",
        "for col in missing_cols:\n",
        "    house_df[col] = 0\n",
        "house_df = house_df[X_train.columns]\n",
        "\n",
        "# Scale the features (Assuming the same scaler used for training)\n",
        "house_df[numerical_features] = scaler.transform(house_df[numerical_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "7Lqj-nY28dkt",
        "outputId": "d9f39b3a-b5f4-4b92-eb26-79eba302adde"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>...</th>\n",
              "      <th>statezip_WA 98178</th>\n",
              "      <th>statezip_WA 98188</th>\n",
              "      <th>statezip_WA 98198</th>\n",
              "      <th>statezip_WA 98199</th>\n",
              "      <th>statezip_WA 98288</th>\n",
              "      <th>statezip_WA 98354</th>\n",
              "      <th>house_age</th>\n",
              "      <th>years_since_renovation</th>\n",
              "      <th>has_basement</th>\n",
              "      <th>total_sqft</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10858</td>\n",
              "      <td>0.00872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.158186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>1.004469</td>\n",
              "      <td>0</td>\n",
              "      <td>0.009646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 138 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
              "0         3          2      0.10858   0.00872     0.0         0.0   0.0   \n",
              "\n",
              "   condition  sqft_above  sqft_basement  ...  statezip_WA 98178  \\\n",
              "0        0.5    0.158186            0.0  ...                  0   \n",
              "\n",
              "   statezip_WA 98188  statezip_WA 98198  statezip_WA 98199  statezip_WA 98288  \\\n",
              "0                  0                  0                  0                  0   \n",
              "\n",
              "   statezip_WA 98354  house_age  years_since_renovation  has_basement  \\\n",
              "0                  0   0.026316                1.004469             0   \n",
              "\n",
              "   total_sqft  \n",
              "0    0.009646  \n",
              "\n",
              "[1 rows x 138 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "house_df.to_csv(\"house_df.csv\")\n",
        "house_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTfXTCI56wJu",
        "outputId": "2ae7291d-e08f-4769-d90e-ebdf7e3f4884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
            "Predicted house price: $870,937.25\n"
          ]
        }
      ],
      "source": [
        "# Predict the price\n",
        "predicted_price = model.predict(house_df)\n",
        "\n",
        "# Output the predicted price\n",
        "print(f\"Predicted house price: ${predicted_price[0][0]:,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wypU7oCK7Mbg"
      },
      "outputs": [],
      "source": [
        "# Save model architecture to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Save model weights\n",
        "model.save_weights(\"model.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Predicted house price: $870,937.25\n"
          ]
        }
      ],
      "source": [
        "#%%\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# Load model architecture from JSON\n",
        "with open('model.json', 'r') as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# Load weights into the new model\n",
        "loaded_model.load_weights(\"model.weights.h5\")\n",
        "\n",
        "# Compile the model if necessary\n",
        "loaded_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "# %%\n",
        "print(f\"Predicted house price: ${loaded_model.predict(house_df)[0][0]:,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'loaded_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(house_df)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
          ]
        }
      ],
      "source": [
        "loaded_model.predict(house_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
